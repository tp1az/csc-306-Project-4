{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ibm_hr = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/066_IBM_HR/sample.parquet\")\n",
    "tripadvisor = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/067_TripAdvisor/sample.parquet\")\n",
    "worldBank = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/068_WorldBank_Awards/sample.parquet\")\n",
    "taxonomy = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/069_Taxonomy/sample.parquet\")\n",
    "openfoodfacts = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/070_OpenFoodFacts/sample.parquet\")\n",
    "col = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/071_COL/sample.parquet\")\n",
    "admissions = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/072_Admissions/sample.parquet\")\n",
    "med_cost = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/073_Med_Cost/sample.parquet\")\n",
    "lift = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/074_Lift/sample.parquet\")\n",
    "mortality = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/075_Mortality/sample.parquet\")\n",
    "nba = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/076_NBA/sample.parquet\")\n",
    "gestational = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/077_Gestational/sample.parquet\")\n",
    "fires = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/078_Fires/sample.parquet\")\n",
    "coffee = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/079_Coffee/sample.parquet\")\n",
    "books = pd.read_parquet(\"/Users/tonypiacentini/csc-306-Project-4/src/data/080_Books/sample.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns = ['DataSet','DataRaw'])\n",
    "data.loc[len(data)] = ['066_IBM_HR', ibm_hr.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['067_TripAdvisor', tripadvisor.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['068_WorldBank_Awards', worldBank.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['069_Taxonomy', taxonomy.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['070_OpenFoodFacts', openfoodfacts.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['071_COL', col.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['072_Admissions', admissions.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['073_Med_Cost', med_cost.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['074_Lift', lift.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['075_Mortality', mortality.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['076_NBA', nba.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['077_Gestational', gestational.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['078_Fires', fires.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['079_Coffee', coffee.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['080_Books', books.to_csv(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.65\n"
     ]
    }
   ],
   "source": [
    "avgAge = (ibm_hr['Age'].sum() / ibm_hr['Age'].count())\n",
    "print(avgAge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Age,Attrition,BusinessTravel,DailyRate,Departm...\n",
      "1     ratings,title,text,author,date_stayed,offering...\n",
      "2     Procurement Method,Fiscal Year,Project Global ...\n",
      "3     Unique ID,Parent,Name,Tier 1,Tier 2,Tier 3,Tie...\n",
      "4     categories_en,code,product_name,brands,labels_...\n",
      "5     Rank,Country,Cost of Living Index,Rent Index,C...\n",
      "6     Serial No.,GRE Score,TOEFL Score,University Ra...\n",
      "7     age,sex,bmi,children,smoker,region,charges\\n19...\n",
      "8     Lifter Name,Age,Weight Class,Lift Type,Amount ...\n",
      "9     rownames,Region,Status,Sex,Cause,Rate,SE\\n5,HH...\n",
      "10    year,Season_type,PLAYER_ID,RANK,PLAYER,TEAM_ID...\n",
      "11    Age,Pregnancy No,Weight,Height,BMI,Heredity,Pr...\n",
      "12    area,X,Y,month,day,DMC,DC,ISI,temp,RH,wind,cal...\n",
      "13    transaction_id,transaction_qty,store_id,store_...\n",
      "14    Book Title,Author,Category,Price (TK),Stock St...\n",
      "Name: DataRaw, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['DataRaw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index('DataSet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataRaw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataSet</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>Age,Attrition,BusinessTravel,DailyRate,Departm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>067_TripAdvisor</th>\n",
       "      <td>ratings,title,text,author,date_stayed,offering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>068_WorldBank_Awards</th>\n",
       "      <td>Procurement Method,Fiscal Year,Project Global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>069_Taxonomy</th>\n",
       "      <td>Unique ID,Parent,Name,Tier 1,Tier 2,Tier 3,Tie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>070_OpenFoodFacts</th>\n",
       "      <td>categories_en,code,product_name,brands,labels_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                DataRaw\n",
       "DataSet                                                                \n",
       "066_IBM_HR            Age,Attrition,BusinessTravel,DailyRate,Departm...\n",
       "067_TripAdvisor       ratings,title,text,author,date_stayed,offering...\n",
       "068_WorldBank_Awards  Procurement Method,Fiscal Year,Project Global ...\n",
       "069_Taxonomy          Unique ID,Parent,Name,Tier 1,Tier 2,Tier 3,Tie...\n",
       "070_OpenFoodFacts     categories_en,code,product_name,brands,labels_..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "066_IBM_HR\n",
      "067_TripAdvisor\n",
      "068_WorldBank_Awards\n",
      "069_Taxonomy\n",
      "070_OpenFoodFacts\n",
      "071_COL\n",
      "072_Admissions\n",
      "073_Med_Cost\n",
      "074_Lift\n",
      "075_Mortality\n",
      "076_NBA\n",
      "077_Gestational\n",
      "078_Fires\n",
      "079_Coffee\n",
      "080_Books\n"
     ]
    }
   ],
   "source": [
    "for name, raw in data.itertuples():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does the dataset contain any review that more than forty users have labeled as helpful?\"\n",
    "dataframe = data.loc['067_TripAdvisor']\n",
    "result_df1 = openai_test.response_test(query, dataframe['DataRaw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Answer\": \"False\"}\n"
     ]
    }
   ],
   "source": [
    "print(result_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>List the titles of books with fewer than 200 p...</td>\n",
       "      <td>080_Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>List the categories of books with ratings abov...</td>\n",
       "      <td>080_Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>List the authors of books with more than 10 re...</td>\n",
       "      <td>080_Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>List the 5 categories of the last five books i...</td>\n",
       "      <td>080_Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>List the editions of books in the 'Business, I...</td>\n",
       "      <td>080_Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question    dataset\n",
       "517  List the titles of books with fewer than 200 p...  080_Books\n",
       "518  List the categories of books with ratings abov...  080_Books\n",
       "519  List the authors of books with more than 10 re...  080_Books\n",
       "520  List the 5 categories of the last five books i...  080_Books\n",
       "521  List the editions of books in the 'Business, I...  080_Books"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qa = pd.read_csv(\"/Users/tonypiacentini/csc-306-Project-4/src/data/test_qa.csv\")  \n",
    "test_qa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qa = test_qa.set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n"
     ]
    }
   ],
   "source": [
    "runner = 0\n",
    "last_name = \"\"\n",
    "final = []\n",
    "for name, query in test_qa.itertuples():\n",
    "    \n",
    "    if (runner % 10 == 0):\n",
    "        print(runner)\n",
    "    dataframe = data.loc[name]\n",
    "    result = openai_test.response_test(query, dataframe['DataRaw'])\n",
    "    result = result.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "    final.append(result)\n",
    "    runner += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'Answer'\", \" 'True'\"]\n",
      "Still an error: Expecting value: line 1 column 1 (char 0)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final[0].split(\":\"))\n",
    "print(fix_and_parse_json(final[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(final: list):\n",
    "    answers = []\n",
    "    for i in final:\n",
    "        ans = i.split(\":\")[1]\n",
    "        answers.append(ans.replace(\"\\n\", \"\").replace(\"'\", \"\").replace(\"```\",\"\").replace('\"',\"\").replace(\" \",\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_string(s):\n",
    "    \"\"\"Convert a string to a list, boolean, or float if possible.\"\"\"\n",
    "    \n",
    "    # Try converting to a boolean first\n",
    "    if s.lower() == \"true\" or s.lower() == \"yes\" or s.lower() == \"y\":\n",
    "        return True\n",
    "    elif s.lower() == \"false\" or s.lower() == \"no\" or s.lower() == \"n\":\n",
    "        return False\n",
    "\n",
    "    # Try converting to a float\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Try converting to a list using ast.literal_eval\n",
    "    try:\n",
    "        if(len(s) != 0):\n",
    "            list_val = []\n",
    "            if s[0] == \"[\" and s[-1] == \"]\":\n",
    "                for i in s.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"):\n",
    "                    list_val.append(convert_string(i))\n",
    "                return list_val\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # If no conversion is possible, return the original string\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = []\n",
    "for i in answers:\n",
    "    valid.append(convert_string(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 1.0, 4.0, 3.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "print(valid[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(prompts: list[str]):\n",
    "    result_list = []\n",
    "    for p in prompts:\n",
    "        dataframe = data.loc[name]\n",
    "        result = openai_test.response_test(query, dataframe['DataRaw'])\n",
    "        result = result.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "        result_list.append(result)\n",
    "    final = clean(result_list)\n",
    "    for i in final:\n",
    "        converted = convert_string(i)\n",
    "    return converted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "semeval_train_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"train\")\n",
    "semeval_dev_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'type', 'columns_used', 'column_types', 'sample_answer', 'dataset'],\n",
      "    num_rows: 1308\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(all_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qa = load_dataset(\"cardiffnlp/databench\", name=\"qa\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.DataFrame()\n",
    "\n",
    "# Read the answers from the .txt files into separate lists\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/answers.txt\", \"r\") as f:\n",
    "    answers = f.read().splitlines()\n",
    "\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/answers_lite.txt\", \"r\") as f:\n",
    "    sample_answers = f.read().splitlines()\n",
    "\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/semantics.txt\", \"r\") as f:\n",
    "    semantics = f.read().splitlines()\n",
    "\n",
    "# Combine the lists into a DataFrame\n",
    "\n",
    "# Load the dataset column from the specified file\n",
    "test_qa[\"answer\"] = answers\n",
    "test_qa[\"sample_answer\"] = sample_answers\n",
    "test_qa[\"type\"] = semantics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shlex\n",
    "import zipfile\n",
    "\n",
    "from datasets import Dataset\n",
    "from databench_eval import Runner, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = Dataset.from_pandas(test_qa.head(100))\n",
    "evaluator = Evaluator(qa=qa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 15885.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBench_lite accuracy is 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataBench_lite accuracy is {evaluator.eval(valid, lite=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
