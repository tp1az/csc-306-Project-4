{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rich\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shlex\n",
    "import zipfile\n",
    "\n",
    "from datasets import Dataset\n",
    "from databench_eval import Runner, Evaluator\n",
    "import openai_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(type = 'sample'):\n",
    "    ibm_hr = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/066_IBM_HR/{type}.parquet\")\n",
    "    tripadvisor = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/067_TripAdvisor/{type}.parquet\")\n",
    "    worldBank = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/068_WorldBank_Awards/{type}.parquet\")\n",
    "    taxonomy = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/069_Taxonomy/{type}.parquet\")\n",
    "    openfoodfacts = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/070_OpenFoodFacts/{type}.parquet\")\n",
    "    col = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/071_COL/{type}.parquet\")\n",
    "    admissions = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/072_Admissions/{type}.parquet\")\n",
    "    med_cost = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/073_Med_Cost/{type}.parquet\")\n",
    "    lift = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/074_Lift/{type}.parquet\")\n",
    "    mortality = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/075_Mortality/{type}.parquet\")\n",
    "    nba = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/076_NBA/{type}.parquet\")\n",
    "    gestational = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/077_Gestational/{type}.parquet\")\n",
    "    fires = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/078_Fires/{type}.parquet\")\n",
    "    coffee = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/079_Coffee/{type}.parquet\")\n",
    "    books = pd.read_parquet(f\"/Users/tonypiacentini/csc-306-Project-4/src/data/080_Books/{type}.parquet\")\n",
    "    data = pd.DataFrame(columns = ['DataSet','DataRaw'])\n",
    "    data.loc[len(data)] = ['066_IBM_HR', ibm_hr.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['067_TripAdvisor', tripadvisor.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['068_WorldBank_Awards', worldBank.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['069_Taxonomy', taxonomy.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['070_OpenFoodFacts', openfoodfacts.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['071_COL', col.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['072_Admissions', admissions.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['073_Med_Cost', med_cost.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['074_Lift', lift.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['075_Mortality', mortality.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['076_NBA', nba.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['077_Gestational', gestational.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['078_Fires', fires.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['079_Coffee', coffee.to_csv(index=False)]\n",
    "    data.loc[len(data)] = ['080_Books', books.to_csv(index=False)]\n",
    "    data = data.set_index('DataSet')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = load_dataset()\n",
    "#d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d['DataRaw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, raw in d.itertuples():\n",
    "#    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"Does the dataset contain any review that more than forty users have labeled as helpful?\"\n",
    "#dataframe = d.loc['067_TripAdvisor']\n",
    "#result_df1 = openai_test.response_test(query, dataframe['DataRaw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_qa = pd.read_csv(\"/Users/tonypiacentini/csc-306-Project-4/src/data/test_qa.csv\")  \n",
    "#test_qa.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(test_qa, data):\n",
    "    runner = 0\n",
    "    last_name = \"\"\n",
    "    final = []\n",
    "    for name, query in test_qa.itertuples():\n",
    "        if(runner % 10 == 0):\n",
    "            print(runner)\n",
    "        dataframe = data.loc[name]\n",
    "        result = openai_test.response_test(query, dataframe['DataRaw'])\n",
    "        result = result.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "        final.append(result)\n",
    "        runner += 1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answers = get_answers(test_qa, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(final: list):\n",
    "    ans_list = []\n",
    "    for i in final:\n",
    "        ans = i.split(\":\")[1]\n",
    "        ans_list.append(ans.replace(\"\\n\", \"\").replace(\"'\", \"\").replace(\"```\",\"\").replace('\"',\"\"))#.replace(\"\",\"\"))\n",
    "    return ans_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_string(s):\n",
    "    \"\"\"Convert a string to a list, boolean, or float if possible.\"\"\"\n",
    "    s = s.strip()\n",
    "    # Try converting to a boolean first\n",
    "    if s.lower() == \"true\" or s.lower() == \"yes\" or s.lower() == \"y\":\n",
    "        return True\n",
    "    elif s.lower() == \"false\" or s.lower() == \"no\" or s.lower() == \"n\":\n",
    "        return False\n",
    "    try:\n",
    "        int_val = int(s)\n",
    "        if str(int_val) == s:  # Ensure it's a true integer (not \"3.14\")\n",
    "            return int_val\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # Try converting to a float\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    if(len(s) != 0):\n",
    "        list_val = []\n",
    "        if s[0] == \"[\" and s[-1] == \"]\":\n",
    "            for i in s.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"):\n",
    "                list_val.append(convert_string(i))\n",
    "            return list_val\n",
    "\n",
    "    # If no conversion is possible, return the original string\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_answers(answers):\n",
    "    valid = []\n",
    "    clean_answers = clean(answers)\n",
    "    for i in clean_answers:\n",
    "        valid.append(convert_string(i))\n",
    "    return valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qa = pd.read_csv(\"/Users/tonypiacentini/csc-306-Project-4/src/data/test_qa.csv\")  \n",
    "test_qa = test_qa.set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lite = load_dataset()\n",
    "data_all = load_dataset(type = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n"
     ]
    }
   ],
   "source": [
    "answers_lite = get_answers(test_qa, data_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answers_all = get_answers(test_qa, data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_lite = reformat_answers(answers_lite)\n",
    "#reformatted_all = reformat_answers(answers_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code to set up the evaluator with the correct answers to the test_qa.csv. This code, the answers, as well as the answer types comes from the databench_eval github under their competition_baseline.py file. Using this we are able to correctly evaluate using the test_qa questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.DataFrame()\n",
    "qaa = test_qa\n",
    "# Read the answers from the .txt files into separate lists\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/answers.txt\", \"r\") as f:\n",
    "    answers = f.read().splitlines()\n",
    "\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/answers_lite.txt\", \"r\") as f:\n",
    "    sample_answers = f.read().splitlines()\n",
    "\n",
    "with open(\"/Users/tonypiacentini/csc-306-Project-4/src/data/semantics.txt\", \"r\") as f:\n",
    "    semantics = f.read().splitlines()\n",
    "\n",
    "# Combine the lists into a DataFrame\n",
    "\n",
    "# Load the dataset column from the specified file\n",
    "qaa[\"answer\"] = answers\n",
    "qaa[\"sample_answer\"] = sample_answers\n",
    "qaa[\"type\"] = semantics\n",
    "\n",
    "qa = Dataset.from_pandas(qaa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['```json\\n\"Answer\":\"True\"\\n```', \"'Answer': 'Yes'\", '```json\\n\"Answer\":false\\n```', '\"Answer\":\"False\"', \"'Answer': 'False'\", \"'Answer': 'False'\", '```json\\n\"Answer\":\"False\"\\n```', '```json\\n\"Answer\": \"True\"\\n```', \"'Answer': 'True'\", '```json\\n\"Answer\":\"Laboratory Technician\"\\n```', '```json\\n\"Answer\":\"Research & Development\"\\n```', \"'Answer': 'Divorced'\", '```json\\n\"Answer\":\"Life Sciences\"\\n```', '```json\\n\"Answer\":\"Sales\"\\n```', '```json\\n\"Answer\":\"Female\"\\n```', '```json\\n\"Answer\":\"3\"\\n```', '```json\\n\"Answer\":\"Other\"\\n```', \"'Answer': 37\", '```json\\n\"Answer\":5\\n```', '```json\\n\"Answer\":31\\n```', \"'Answer': 2991\", '\\n  \"Answer\": 510\\n', '```json\\n\"Answer\":31\\n```', '```json\\n\"Answer\":4\\n```', '```json\\n\"Answer\": 24\\n```', '```json\\n\"Answer\":8\\n```', \"'Answer': '['3', '4', '2', '1']'\", '```json\\n\"Answer\": [2028, 2090, 2426, 2661, 2693]\\n```', '```json\\n\"Answer\": \"[1, 2, 3, 4]\"\\n```', '\\n  \"Answer\": \"[11, 11, 11, 11, 11]\"\\n', \"'Answer': '[41, 49, 37, 33, 27]'\", '```json\\n\"Answer\": \"[\\'Laboratory Technician\\', \\'Research Scientist\\', \\'Sales Executive\\']\"\\n```', '\\'Answer\\': \\'[\"Sales\", \"Research & Development\"]\\'', '```json\\n\"Answer\": \"[\\'Single\\', \\'Married\\', \\'Divorced\\']\"\\n```', '```json\\n\"Answer\": \"[Life Sciences, Other, Medical]\"\\n```', \"'Answer': '['Travel_Rarely', 'Travel_Frequently', 'Non-Travel']'\", '```json\\n\"Answer\":\"[Yes, No]\"\\n```', '\\'Answer\\': \\'[\"2\", \"1\", \"3\", \"4\"]\\'', \"'Answer': ['1', '2', '3']\", \"'Answer': 'False'\", \"'Answer': False\", \"'Answer': False\", '\"Answer\":10', \"'Answer': 'False'\", '```json\\n\"Answer\":\"False\"\\n```', \"'Answer': False\", \"'Answer': 'False'\", \"'Answer': True\", \"'Answer': 'False'\", \"'Answer': '2012'\", \"'Answer': 3.3\", '```json\\n\"Answer\": \"5.0\"\\n```', \"'Answer': 0\", \"'Answer': 'charlietrisj'\", '\"Answer\":99', \"'Answer': 25\", '```json\\n\"Answer\":35\\n```', '\"Answer\":10.6875', \"'Answer': 614\", \"'Answer': 2004\", '```json\\n\"Answer\":1\\n```', '```json\\n\"Answer\":173\\n```', '```json\\n\"Answer\": [\"2012\", \"2011\", \"2010\", \"2009\"]\\n```', '```json\\n\"Answer\": [123, 70, 40, 35, 23]\\n```', \"```json\\n'Answer': ['marknthedark', 'Largeandy', 'Pressgang', 'scottlove', 'cmd123', 'a300zx4pak', 'euronovice']\\n```\", '```json\\n\"Answer\": \"[\\'marknthedark\\', \\'cmd123\\', \\'IndustryBuff\\', \\'oahulady66\\', \\'a300zx4pak\\', \\'busyvatraveler\\']\"\\n```', '```json\\n\"Answer\": \"[111492, 108562, 94354, 98798, 93889]\"\\n```', '\\n    \"Answer\": \"[2010, 2009, 2007, 2012]\"\\n', \"'Answer': False\", \"'Answer': 'False'\", '```json\\n\"Answer\": \"False\"\\n```', \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': 'False'\", '\"Answer\": \"False\"', '\"Answer\":\"Request for Quotations\"', '```json\\n\"Answer\":\"Western and Central Africa\"\\n```', '```json\\n\"Answer\":\"Federated States of Micronesia\"\\n```', '\\n  \"Answer\": \"Civil Works\"\\n', '```json\\n\"Answer\":\"Western and Central Africa\"\\n```', '```json\\n\"Answer\":\"Burkina Faso\"\\n```', \"'Answer': 'Consultant Qualification  Selection'\", '```json\\n\"Answer\":800433.3\\n```', \"'Answer': 3\", \"'Answer': 20\", \"'Answer': 181470.31\", \"'Answer': 999999.0\", \"'Answer': 195267.1838643616\", '```json\\n\"Answer\":6\\n```', \"```json\\n'Answer': [800433.3, 716716.34, 369866.76]\\n```\", '```json\\n\"Answer\":\"True\"\\n```', '```json\\n\"Answer\":[754040.0,999999.0,879159.0,879141.0,879138.0]\\n```', \"'Answer': ['2025', '2024', '2023']\", '\\n  \"Answer\": [\\n    0.0,\\n    0.0,\\n    0.0\\n  ]\\n', \"```json\\n'Answer': '[186884.26, 198952.48]'\\n```\", \"```json\\n'Answer': [716716.34, 800433.3, 369866.76, 186884.26]\\n```\", '\\n  \"Answer\": \"[Ghana, Burkina Faso, Nigeria, Niger, Ethiopia]\"\\n', '\\n  \"Answer\": \"[Western and Central Africa, Eastern and Southern Africa, LATIN AMERICA AND CARIBBEAN, EAST ASIA AND PACIFIC]\"\\n', '```json\\n\"Answer\": [\"Request for Quotations\", \"Request for Bids\", \"Individual Consultant Selection\", \"Consultant Qualification  Selection\"]\\n```', '```json\\n\"Answer\": [\"Ghana\", \"Micronesia, Federated States of\", \"Burkina Faso\", \"Nigeria\"]\\n```', '```json\\n\"Answer\": \"[Request for Bids, Consultant Qualification  Selection, Individual Consultant Selection, Direct Selection, Request for Quotations]\"\\n```', '```json\\n\"Answer\": \"[Request for Bids, Request for Quotations, Individual Consultant Selection, Direct Selection, Consultant Qualification  Selection]\"\\n```', \"'Answer': 'True'\", \"'Answer': 'True'\", '```json\\n\"Answer\":\"True\"\\n```', \"'Answer': 'False'\", \"'Answer': False\", \"'Answer': 'False'\", \"'Answer': 'False'\", \"'Answer': 'True'\", '```json\\n\"Answer\":\"Attractions\"\\n```', '```json\\n\"Answer\":\"Attractions\"\\n```', '```json\\n\"Answer\":\"Attractions\"\\n```', '```json\\n\"Answer\":\"Amusement and Theme Parks\"\\n```', '```json\\n\"Answer\":\"150\"\\n```', '\"Answer\":\"Amusement and Theme Parks\"', '```json\\n\"Answer\":\"Attractions\"\\n```', \"'Answer': 12\", \"'Answer': 2\", '\\n    \"Answer\": 10\\n', \"'Answer': 6\", '```json\\n\"Answer\":10\\n```', \"'Answer': 0\", \"'Answer': 0\", \"'Answer': 'False'\", '\"Answer\":12', '```json\\n\"Answer\": [\"Attractions\", \"Automotive\", \"Automotive\"]\\n```', '\\n  \"Answer\": [12, 7]\\n', \"'Answer': [0, 0]\", '\\n  \"Answer\": [12, 9, 0, 0]\\n', \"'Answer': ['Attractions', 'Automotive', 'Amusement and Theme Parks']\", \"```json\\n'Answer': ['Attractions', 'Automotive']\\n```\", \"```json\\n'Answer': ['Amusement and Theme Parks', 'Bars & Restaurants', 'Casinos & Gambling', 'Historic Site and Landmark Tours']\\n```\", '```json\\n\"Answer\": \"[Attractions, Automotive]\"\\n```', '\\n  \"Answer\": \"[Attractions, Attractions, Attractions, Attractions]\"\\n', '\\n  \"Answer\": [\"Attractions\", \"Automotive\"]\\n', '\\n  \"Answer\": [\\n    \"Attractions\",\\n    \"Automotive\"\\n  ]\\n', \"'Answer': 'True'\", '\"Answer\":\"True\"', \"'Answer': 'True'\", \"'Answer': 'True'\", \"'Answer': True\", '\"Answer\":\"False\"', '\"Answer\": \"False\"', '```json\\n\"Answer\":\"True\"\\n```', '```json\\n\"Answer\":\"Hacendado\"\\n```', \"'Answer': 'Spain'\", '```json\\n\"Answer\":\"Hacendado\"\\n```', '```json\\n\"Answer\": 1\\n```', '```json\\n\"Answer\":\"Mercadona\"\\n```', '```json\\n\"Answer\":\"kiliweb\"\\n```', \"'Answer': 15\", '```json\\n\"Answer\":2\\n```', '```json\\n\"Answer\":8\\n```', '\\n  \"Answer\": 8\\n', '```json\\n\"Answer\":7\\n```', '```json\\n\"Answer\":9\\n```', '\"Answer\":2', '\\'Answer\\': \\'[\"00001522\"]\\'', '```json\\n\"Answer\": \"[Seitán a la plancha]\"\\n```', '```json\\n\"Answer\": [\"Hacendado\", \"Mercadona\"]\\n```', '\\'Answer\\': \\'[\"Hacendado\", \"Mercadona\", \"Green Dot\", \"No gluten\", \"Vegetarian\"]\\'', \"```json\\n'Answer': ['Hacendado', 'Mercadona']\\n```\", \"'Answer': [2, 7]\", '```json\\n\"Answer\": [\"Spain\"]\\n```', \"```json\\n'Answer': [28, 3, 2]\\n```\", \"'Answer': 'True'\", \"'Answer': True\", '\"Answer\":\"True\"', \"'Answer': 'True'\", \"'Answer': 'False'\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': 'True'\", '```json\\n\"Answer\":\"Switzerland\"\\n```', \"'Answer': 'Bahamas'\", \"'Answer': 'Bahamas'\", \"'Answer': 'Switzerland'\", \"'Answer': 'Bahamas'\", \"'Answer': 'Bahamas'\", '```json\\n\"Answer\":\"Bahamas\"\\n```', \"'Answer': 101.1\", \"'Answer': 46.5\", \"'Answer': 20\", \"'Answer': 67.65\", \"'Answer': 50.6\", \"'Answer': 76.7\", '\\n  \"Answer\": 115.84\\n', \"'Answer': 3\", '\\n  \"Answer\": \"[46.5, 36.7, 39.2, 67.2, 19.0]\"\\n', '\"Answer\": \"[101.1, 85.0, 83.0, 76.7, 76.6]\"', '\\n  \"Answer\": \"[158.7, 54.6, 120.3, 111.1, 43.5]\"\\n', \"'Answer': [109.1, 81.6, 88.4]\", \"'Answer': ['97.0', '83.3', '86.8', '50.4', '69.4']\", '\\n  \"Answer\": [\"Bahamas\", \"Iceland\", \"Singapore\", \"Barbados\", \"Norway\"]\\n', '\\n  \"Answer\": \"[120.3, 111.1, 114.7, 127.2, 127.4]\"\\n', '\\n  \"Answer\": \"[\\\\\"Switzerland\\\\\", \\\\\"Bahamas\\\\\", \\\\\"Iceland\\\\\", \\\\\"Singapore\\\\\", \\\\\"Barbados\\\\\"]\"\\n', \"'Answer': ['Switzerland', 'Iceland', 'Bahamas']\", \"'Answer': ['Bahamas', 'Barbados', 'Norway']\", \"'Answer': ['Australia', 'Austria', 'Canada', 'New Zealand', 'Ireland', 'France']\", '```json\\n\\n  \"Answer\": [\"Switzerland\", \"Iceland\", \"Singapore\", \"Norway\", \"Denmark\"]\\n\\n```', '\\'Answer\\': \\'[\"Bahamas\", \"Iceland\", \"Singapore\"]\\'', \"'Answer': 'True'\", \"'Answer': True\", \"'Answer': 'True'\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': True\", \"'Answer': True\", \"'Answer': 'False'\", \"'Answer': '5'\", \"'Answer': '1'\", \"'Answer': '3'\", '```json\\n\"Answer\":3.0\\n```', \"'Answer': '1'\", '```json\\n\"Answer\":\"5\"\\n```', \"'Answer': '3'\", \"'Answer': 'Yes'\", '```json\\n\"Answer\":337\\n```', \"'Answer': 0.72\", \"'Answer': 9\", \"'Answer': 8.5\", \"```json\\n'Answer': 314\\n```\", \"'Answer': 0.5710511687605817\", \"'Answer': 0\", '```json\\n\"Answer\":0\\n```', '\\n  \"Answer\": [337, 330, 328, 327, 325]\\n', \"'Answer': 0\", \"'Answer': 4\", \"'Answer': '[337, 334, 330, 328, 327]'\", \"'Answer': [7.9, 8.0, 8.0, 8.21, 8.3]\", \"'Answer': [4.5, 4.0, 3.5, 2.0, 3.0]\", \"'Answer': '[4.5, 4.5, 4.0, 4.5, 4.0]'\", \"'Answer': '[118, 115, 112, 111, 110]'\", '```json\\n\"Answer\": [337, 330]\\n```', '```json\\n\"Answer\": [7.9, 8.21]\\n```', \"'Answer': ['4', '4', '5', '4', '4']\", \"'Answer': ['2', '2', '3', '3', '3']\", \"'Answer': ['4.5', '4.5', '9.65', '1', '0.92', '4.0', '4.5', '8.87', '1', '0.76', '4.5', '3.0', '9.34', '1', '0.9', '4.0', '4.5', '9.0', '1', '0.84']\", '\\n  \"Answer\": \"[4.5, 4.0, 4.0, 4.5, 4.0]\"\\n', \"'Answer': '[3.5, 3.0, 2.5, 3.0, 2.0]'\", \"'Answer': False\", \"'Answer': 'True'\", \"'Answer': False\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': 'True'\", \"'Answer': 'Yes'\", \"'Answer': 'False'\", \"'Answer': 'False'\", \"'Answer': 'southeast'\", \"'Answer': 'female'\", \"'Answer': 'yes'\", \"'Answer': 'southeast'\", \"'Answer': 'female'\", \"'Answer': 'False'\", \"'Answer': 0\", \"'Answer': 'northeast'\", \"'Answer': 'no'\", \"'Answer': 42.13\", \"'Answer': 1.0\", \"'Answer': 4\", \"'Answer': 201305.00804\", \"'Answer': 18\", \"'Answer': 3\", \"'Answer': 4\", \"'Answer': 27.9\", \"'Answer': [42.13, 40.3]\", \"'Answer': ['39611.7577', '36837.467', '11090.7178']\", '```json\\n\"Answer\":[18,19,23,23,25]\\n```', \"'Answer': [18, 19, 19]\", \"'Answer': ['no', 'yes']\", '\\n  \"Answer\": \"[southeast, southeast, southwest]\"\\n', \"'Answer': 'True'\", \"'Answer': 'True'\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': 'False'\", '\"Answer\":\"True\"', \"'Answer': 'False'\", \"'Answer': '74 kg'\", '\"Answer\":\"74 kg\"', \"'Answer': 'Bench Press'\", \"'Answer': 398\", \"'Answer': 8\", \"'Answer': 5\", \"'Answer': 5\", \"'Answer': 398\", \"'Answer': 269\", \"'Answer': 'Emily Davis'\", \"'Answer': 1381\", \"'Answer': 133\", '\"Answer\":219', \"'Answer': 5\", \"'Answer': ['398', '396', '396']\", \"'Answer': ['132', '178', '179', '221', '235']\", \"'Answer': ['Matthew Anderson', 'Laura Taylor', 'Emily Davis', 'Chris Brown', 'Jessica Wilson']\", '```json\\n\"Answer\":[\"Weight Class\":\"59 kg\",\"Age Gap\":34,\"Weight Class\":\"74 kg\",\"Age Gap\":36,\"Weight Class\":\"83 kg\",\"Age Gap\":20]\\n```', \"'Answer': ['Emily Davis', 'Emily Davis']\", \"'Answer': ['359', '265', '264']\", \"```json\\n'Answer': ['Jessica Wilson', 'Emily Davis', 'Laura Taylor', 'Sarah Thomas', 'Jane Smith']\\n```\", '```json\\n\"Answer\": [\"John Doe\", \"Michael Johnson\", \"Chris Brown\", \"Daniel Lee\", \"Matthew Anderson\"]\\n```', '```json\\n\"Answer\": \"[\\'74 kg\\', \\'120 kg\\', \\'83 kg\\']\"\\n```', '\\n  \"Answer\": [\\n    \"Laura Taylor\",\\n    \"Sarah Thomas\",\\n    \"Matthew Anderson\",\\n    \"Jane Smith\",\\n    \"Laura Taylor\"\\n  ]\\n', '\\'Answer\\': \\'[\"Squat\", \"Deadlift\", \"Bench Press\"]\\'', '\\n  \"Answer\": \"[\\'Bench Press\\', \\'Deadlift\\', \\'Squat\\']\"\\n', \"'Answer': 'False'\", \"'Answer': 'True'\", '\"Answer\":\"True\"', '\\n  \"Answer\": \"True\"\\n', \"'Answer': 'False'\", \"'Answer': 'False'\", \"'Answer': False\", \"'Answer': 'True'\", \"'Answer': 'HHS Region 04'\", '\"Answer\":\"Heart disease\"', '\\n  \"Answer\": \"Male\"\\n', \"'Answer': 'Rural'\", '\\n  \"Answer\": \"HHS Region 01\"\\n', \"'Answer': 276.4\", '\"Answer\":0.4', '\"Answer\":5', '\\n    \"Answer\": 3062.6\\n', \"'Answer': 194.4\", \"'Answer': 'Number'\", '\"Answer\":5', \"'Answer': 161.2\", '\"Answer\":[276.4,248.8,246.0,229.0,226.8]', \"'Answer': [0.4, 0.5, 0.5, 0.6, 0.6]\", '\"Answer\": [115.1, 124.5, 138.1, 132.2, 139.6]', \"'Answer': [226.8, 222.5, 218.2, 212.8]\", \"'Answer': [115.1, 124.5, 138.1, 132.2, 139.6]\", \"'Answer': '['Heart disease']'\", '\\n  \"Answer\": [\"HHS Region 04\", \"HHS Region 02\", \"HHS Region 03\"]\\n', \"'Answer': ['Urban', 'Rural']\", \"'Answer': False\", \"'Answer': 'True'\", \"'Answer': 'False'\", '```json\\n\"Answer\":\"False\"\\n```', \"'Answer': 'True'\", '```json\\n\"Answer\":false\\n```', \"'Answer': 'True'\", '```json\\n\"Answer\":\"False\"\\n```', \"'Answer': 'Kevin Durant'\", \"'Answer': 'Kevin Durant'\", \"'Answer': 'Kevin Durant'\", '```json\\n\"Answer\":\"Kobe Bryant\"\\n```', '```json\\n\"Answer\":\"886\"\\n```', '```json\\n\"Answer\":\"Kevin Durant\"\\n```', '```json\\n\"Answer\":\"169\"\\n```', '```json\\n\"Answer\":145\\n```', \"'Answer': 6700\", \"'Answer': 10466\", \"'Answer': 0\", \"'Answer': 81\", \"'Answer': 604\", '```json\\n\"Answer\":0\\n```', \"'Answer': 0\", '```json\\n\"Answer\":105\\n```', '\\n  \"Answer\": [\"640\", \"610\", \"640\"]\\n', '```json\\n\"Answer\":[551,469,374]\\n```', '```json\\n\"Answer\":\"[2280, 2133, 2036, 2023]\"\\n```', '```json\\n\"Answer\":[2,1,2]\\n```', '```json\\n\"Answer\": [105, 91, 67]\\n```', '\\n  \"Answer\": [\\n    \"Carmelo Anthony\",\\n    \"Dwyane Wade\",\\n    \"LaMarcus Aldridge\",\\n    \"Brook Lopez\",\\n    \"Kemba Walker\"\\n  ]\\n', '```json\\n\"Answer\": [\"Kevin Durant\", \"LeBron James\", \"James Harden\"]\\n```', '\\n  \"Answer\": [\\n    \"OKC\",\\n    \"LAL\",\\n    \"MIA\",\\n    \"HOU\",\\n    \"NYK\"\\n  ]\\n', \"```json\\n'Answer': ['OKC', 'LAL', 'MIA', 'HOU', 'NYK']\\n```\", '```json\\n\"Answer\": [\"Kevin Durant\", \"Kobe Bryant\"]\\n```', '```json\\n\"Answer\": [\"Kevin Durant\", \"Kobe Bryant\", \"LeBron James\"]\\n```', '```json\\n\"Answer\":[\"Kevin Durant\",\"Kobe Bryant\",\"LeBron James\",\"James Harden\"]\\n```', \"'Answer': False\", \"'Answer': 'True'\", \"'Answer': True\", \"'Answer': 'True'\", \"'Answer': 'False'\", \"'Answer': 'True'\", \"'Answer': False\", \"'Answer': 10\", \"'Answer': 'False'\", \"'Answer': 1\", '\"Answer\":19', \"'Answer': 180\", \"'Answer': '1'\", \"'Answer': '23.1'\", \"'Answer': 55\", \"'Answer': 1.47\", \"'Answer': 22.18\", \"'Answer': 0\", '\"Answer\":17', \"'Answer': 10\", \"'Answer': 35\", \"'Answer': 2.59\", \"'Answer': '[180, 165, 165]'\", \"'Answer': '[16, 17, 18]'\", \"'Answer': []\", \"'Answer': '[]'\", \"'Answer': '[0, 1]'\", \"'Answer': '[0]'\", \"'Answer': '[165, 180]'\", \"'Answer': []\", '```json\\n\"Answer\": \"[16, 17]\"\\n```', \"'Answer': True\", '\"Answer\":\"False\"', '\"Answer\":false', '```json\\n\"Answer\":\"False\"\\n```', '```json\\n\"Answer\":\"False\"\\n```', \"'Answer': False\", \"'Answer': False\", \"'Answer': False\", '```json\\n\"Answer\":\"True\"\\n```', '```json\\n\"Answer\":6\\n```', '```json\\n\"Answer\":3\\n```', \"'Answer': 'February'\", '```json\\n\"Answer\":\"7\"\\n```', '```json\\n\"Answer\":\"February\"\\n```', '```json\\n\"Answer\":\"February\"\\n```', '```json\\n\"Answer\":\"2\"\\n```', '```json\\n\"Answer\":\"Monday\"\\n```', '```json\\n\"Answer\":145.4\\n```', '\"Answer\":0.9', '```json\\n\"Answer\":0.0\\n```', \"'Answer': 8\", \"'Answer': 30.3\", \"'Answer': 619.6\", '```json\\n\"Answer\":3.345328132045984\\n```', '\"Answer\":20', \"```json\\n'Answer': [145.4, 141.2, 133.3]\\n```\", \"'Answer': [70.8, 77.5, 80.8, 94.3, 97.1]\", '\\n  \"Answer\": \"[5, 4, 6, 7, 8, 0]\"\\n', '```json\\n\"Answer\": \"[33, 33, 27, 27]\"\\n```', \"```json\\n'Answer': [145.4, 141.2, 133.3, 129.5, 126.5]\\n```\", '```json\\n\"Answer\":\"[145.4, 133.3, 129.5]\"\\n```', '```json\\n\"Answer\": [26.2, 27.4, 27.9]\\n```', '```json\\n\"Answer\":[\"February\",\"August\",\"December\",\"November\",\"January\"]\\n```', '```json\\n\"Answer\": [\"Monday\", \"Wednesday\", \"Saturday\"]\\n```', \"'Answer': ['August', 'November']\", '```json\\n\"Answer\": [\\'February\\', \\'February\\', \\'February\\']\\n```', '```json\\n\"Answer\": \"[\\'August\\', \\'November\\', \\'February\\', \\'December\\']\"\\n```', '```json\\n\"Answer\":\\xa0[\"Tuesday\",\\xa0\"Thursday\",\\xa0\"Monday\",\\xa0\"Saturday\",\\xa0\"Wednesday\"]\\n```', '```json\\n\"Answer\": \"[\\'August\\', \\'November\\', \\'February\\', \\'December\\', \\'Wednesday\\', \\'Monday\\', \\'Thursday\\', \\'Saturday\\', \\'Tuesday\\', \\'Sunday\\']\"\\n```', \"'Answer': 'False'\", \"'Answer': 'False'\", '\"Answer\":\"False\"', \"'Answer': False\", \"'Answer': False\", \"'Answer': 'True'\", \"'Answer': 'Yes'\", \"'Answer': 'False'\", \"'Answer': 'Lower Manhattan'\", \"'Answer': 'Coffee'\", '```json\\n\"Answer\":\"Sun\"\\n```', \"'Answer': 'Drinking Chocolate'\", \"'Answer': 'Jan'\", \"'Answer': 8\", '```json\\n\"Answer\":\"Lower Manhattan\"\\n```', '```json\\n\"Answer\":\"Coffee\"\\n```', \"'Answer': 2\", \"'Answer': 10\", \"'Answer': 87.5\", '\"Answer\":\"Yes\"', \"'Answer': 3.375\", '\"Answer\":20', \"'Answer': 2\", '```json\\n\"Answer\":\"9,00\\xa0US$\"\\n```', \"```json\\n'Answer': 0\\n```\", \"'Answer': '[2, 2, 2]'\", \"'Answer': '[5, 8]'\", '\"Answer\": [2.0, 2.0, 2.0, 2.5]', \"'Answer': ['9,00\\xa0US$', '7,00\\xa0US$', '6,20\\xa0US$']\", \"'Answer': ['2', '2.5', '2.55', '3', '3.1', '3.5', '3.75', '4', '4.25', '4.5', '4.75', '6', '6.2', '7', '9']\", '\\n  \"Answer\": \"[\\'Lower Manhattan\\', \\'Hell\\'s Kitchen\\']\"\\n', '```json\\n\"Answer\": \"[]\"\\n```', \"'Answer': ['Brewed Chai tea', 'Gourmet brewed coffee', 'Hot chocolate']\", '\\n  \"Answer\": \"[Jan]\"\\n', \"```json\\n'Answer': ['Sun']\\n```\", '```json\\n\"Answer\": \"[5, 8]\"\\n```', \"'Answer': ['Brewed Chai tea', 'Hot chocolate']\", \"'Answer': 'Ethiopia Rg'\", \"'Answer': 'True'\", \"'Answer': 'True'\", \"'Answer': 'True'\", '```json\\n\"Answer\": \"True\"\\n```', '```json\\n\"Answer\":false\\n```', \"'Answer': 'False'\", '\"Answer\":\"True\"', \"'Answer': False\", \"'Answer': 'One Hundred Years of Solitude'\", \"'Answer': 'Novel'\", \"'Answer': 1\", '```json\\n\"Answer\":5\\n```', '```json\\n\"Answer\":\"Khaled Hosseini\"\\n```', \"'Answer': 80\", \"'Answer': 'BPB Publications (India)'\", '```json\\n\"Answer\":6.0\\n```', \"'Answer': 'Islamic Books'\", '\"Answer\":8', \"'Answer': 7203\", \"'Answer': 4\", '```json\\n\"Answer\":14.5\\n```', '```json\\n\"Answer\":0\\n```', '\"Answer\":498', \"'Answer': 2\", \"'Answer': 5\", '```json\\n\"Answer\": 24\\n```', '\\n  \"Answer\": \"[498, 640, 80, 512, 492]\"\\n', '\\n  \"Answer\": [498, 640, 80, 512, 492]\\n', \"```json\\n'Answer': [39.0, 30.0, 27.0, 23.0]\\n```\", '```json\\n\"Answer\":\"[492]\"\\n```', '\"Answer\": [4.0, 6.0, 21.0, 38.0, 18.0]', '\\n  \"Answer\": \"[10.0, 13.0, 27.0, 23.0, 11.0]\"\\n', '```json\\n\"Answer\":\"[498, 512]\"\\n```', '```json\\n\"Answer\":5.0\\n```', '\\'Answer\\': \\'[\"History and Tradition\", \" Business, Investment and Economics\", \"Islamic Books\", \"Islamic Books\", \"Computer Science & Engineering\"]\\'', '```json\\n\"Answer\":[\"Harish Bhat\",\"Gianna Moscardo\",\"Bruce Prideaux\",\"Eric Laws\"]\\n```', '\\n  \"Answer\": [\\n    \"Madinah Arabic Reader 1\",\\n    \"Managing Tourism and Hospitality Services\",\\n    \"TataLog Eight Modern Stories from a Timeless Institution\",\\n    \"Train to Pakistan\"\\n  ]\\n', '\\'Answer\\': \\'[\"History and Tradition\", \" Business, Investment and Economics\", \"Novel\", \"Tourism and Hospitality \", \"Biographies, Memories & Interviews\", \"Self-help and meditation\"]\\'', '\\n  \"Answer\": \"[\\'Yuval Noah Harari\\', \\'Benjamin Graham\\', \\'Gabriel Garcia Marquez\\', \\'Khaled Hosseini\\', \\'Peter Thiel\\']\"\\n', \"'Answer': ['Self-help and meditation', 'Self-help and meditation', 'Novel', 'Novel', 'Business, Investment and Economics']\", '```json\\n\"Answer\": \"[\\'8th Impression\\', \\'1st Edition\\', \\'Edition\\']\"\\n```']\n"
     ]
    }
   ],
   "source": [
    "print(answers_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 522/522 [00:00<00:00, 16720.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBench_lite accuracy is 0.4674329501915709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(qa=qa)\n",
    "print(f\"DataBench_lite accuracy is {evaluator.eval(reformatted_lite, lite=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_answer</th>\n",
       "      <th>type</th>\n",
       "      <th>my_answers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>True</td>\n",
       "      <td>boolean</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>True</td>\n",
       "      <td>boolean</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>False</td>\n",
       "      <td>boolean</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>False</td>\n",
       "      <td>boolean</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>066_IBM_HR</th>\n",
       "      <td>True</td>\n",
       "      <td>boolean</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sample_answer     type my_answers\n",
       "dataset                                     \n",
       "066_IBM_HR          True  boolean       True\n",
       "066_IBM_HR          True  boolean       True\n",
       "066_IBM_HR         False  boolean      False\n",
       "066_IBM_HR         False  boolean      False\n",
       "066_IBM_HR          True  boolean      False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myanswers = qaa.drop(columns=['question','answer'])\n",
    "myanswers['my_answers'] = reformatted_lite\n",
    "myanswers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
