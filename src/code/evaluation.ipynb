{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rich\n",
    "import nbimporter\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict, Callable\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "import zipfile\n",
    "\n",
    "from datasets import Dataset\n",
    "from databench_eval import Runner, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_hr = pd.read_parquet(\"../data/066_IBM_HR/sample.parquet\")\n",
    "tripadvisor = pd.read_parquet(\"../data/067_TripAdvisor/sample.parquet\")\n",
    "worldBank = pd.read_parquet(\"../data/068_WorldBank_Awards/sample.parquet\")\n",
    "taxonomy = pd.read_parquet(\"../data/069_Taxonomy/sample.parquet\")\n",
    "openfoodfacts = pd.read_parquet(\"../data/070_OpenFoodFacts/sample.parquet\")\n",
    "col = pd.read_parquet(\"../data/071_COL/sample.parquet\")\n",
    "admissions = pd.read_parquet(\"../data/072_Admissions/sample.parquet\")\n",
    "med_cost = pd.read_parquet(\"../data/073_Med_Cost/sample.parquet\")\n",
    "lift = pd.read_parquet(\"../data/074_Lift/sample.parquet\")\n",
    "mortality = pd.read_parquet(\"../data/075_Mortality/sample.parquet\")\n",
    "nba = pd.read_parquet(\"../data/076_NBA/sample.parquet\")\n",
    "gestational = pd.read_parquet(\"../data/077_Gestational/sample.parquet\")\n",
    "fires = pd.read_parquet(\"../data/078_Fires/sample.parquet\")\n",
    "coffee = pd.read_parquet(\"../data/079_Coffee/sample.parquet\")\n",
    "books = pd.read_parquet(\"../data/080_Books/sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns = ['DataSet','DataRaw'])\n",
    "data.loc[len(data)] = ['066_IBM_HR', ibm_hr.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['067_TripAdvisor', tripadvisor.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['068_WorldBank_Awards', worldBank.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['069_Taxonomy', taxonomy.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['070_OpenFoodFacts', openfoodfacts.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['071_COL', col.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['072_Admissions', admissions.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['073_Med_Cost', med_cost.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['074_Lift', lift.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['075_Mortality', mortality.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['076_NBA', nba.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['077_Gestational', gestational.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['078_Fires', fires.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['079_Coffee', coffee.to_csv(index=False)]\n",
    "data.loc[len(data)] = ['080_Books', books.to_csv(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgAge = (ibm_hr['Age'].sum() / ibm_hr['Age'].count())\n",
    "data = data.set_index('DataSet')\n",
    "query = \"Does the dataset contain any review that more than forty users have labeled as helpful?\"\n",
    "dataframe = data.loc['067_TripAdvisor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_context(df: pd.DataFrame) -> str:\n",
    "    summary = df.describe(include=\"all\").to_string()\n",
    "    return f\"Data Overview:\\n{summary}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_context(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Converts the entire DataFrame to a structured text format.\"\"\"\n",
    "    return f\"Dataset:\\n{df.to_string(index=False)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_ctxt(df: str) -> str:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm_zero_shot(model: str, question: str, context_method: Callable, data: pd.DataFrame) -> str:\n",
    "    context = context_method(data)\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a data analyst answering questions about a company dataset.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Dataset Summary: {context}\\n\\nQuestion: {question}\"},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the dataset contains a review from the user \"cmd123\" that has been labeled as helpful by 123 users.\n"
     ]
    }
   ],
   "source": [
    "result_df1 = query_llm_zero_shot(\"gpt-4o-mini\", query, ret_ctxt, dataframe['DataRaw'])\n",
    "print(result_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qa = pd.read_csv(\"../data/test_qa.csv\")\n",
    "test_qa = test_qa.set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n"
     ]
    }
   ],
   "source": [
    "runner = 0\n",
    "last_name = \"\"\n",
    "final = []\n",
    "for name, query in test_qa.itertuples():\n",
    "    \n",
    "    if (runner % 10 == 0):\n",
    "        print(runner)\n",
    "    dataframe = data.loc[name]\n",
    "    result = query_llm_zero_shot(\"gpt-4o-mini\", query, ret_ctxt, dataframe['DataRaw'])\n",
    "    result = result.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "    final.append(result)\n",
    "    runner += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final[0].split(\":\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(final: list):\n",
    "    answers = []\n",
    "    for i in final:\n",
    "        ans = i.split(\":\")[1]\n",
    "        answers.append(ans.replace(\"\\n\", \"\").replace(\"'\", \"\").replace(\"```\",\"\").replace('\"',\"\").replace(\" \",\"\"))\n",
    "        return answers\n",
    "    \n",
    "answers = clean(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_string(s):\n",
    "    \"\"\"Convert a string to a list, boolean, or float if possible.\"\"\"\n",
    "    \n",
    "    # Try converting to a boolean first\n",
    "    if s.lower() == \"true\" or s.lower() == \"yes\" or s.lower() == \"y\":\n",
    "        return True\n",
    "    elif s.lower() == \"false\" or s.lower() == \"no\" or s.lower() == \"n\":\n",
    "        return False\n",
    "\n",
    "    # Try converting to a float\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Try converting to a list using ast.literal_eval\n",
    "    try:\n",
    "        if(len(s) != 0):\n",
    "            list_val = []\n",
    "            if s[0] == \"[\" and s[-1] == \"]\":\n",
    "                for i in s.replace(\"[\",\"\").replace(\"]\",\"\").split(\",\"):\n",
    "                    list_val.append(convert_string(i))\n",
    "                return list_val\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "\n",
    "    # If no conversion is possible, return the original string\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid = []\n",
    "for i in answers:\n",
    "    valid.append(convert_string(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(prompts: list[str]):\n",
    "    result_list = []\n",
    "    for p in prompts:\n",
    "        dataframe = data.loc[name]\n",
    "        result = query_llm_zero_shot(\"gpt-4o-mini\", query, ret_ctxt, dataframe['DataRaw'])\n",
    "        result = result.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "        result_list.append(result)\n",
    "    final = clean(result_list)\n",
    "    for i in final:\n",
    "        converted = convert_string(i)\n",
    "    return converted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Using Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ade2cfdf5241ed9a9c57ef9b6183b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6d83b13235412bb6341c67cc94fc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f6643a4ecf4762a0bdc5520e7609a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b988663f13d44f028128f0693655c521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semeval_train_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"train\")\n",
    "semeval_dev_qa = load_dataset(\"cardiffnlp/databench\", name=\"semeval\", split=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a2b7c6cea2486d9104a5d2a6eb9ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b1ec32df7448998a430c016a4010b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691279294bf949528b4cf366fe7013dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/65 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976ee7cc580f4a9794a47dec80f0f23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'type', 'columns_used', 'column_types', 'sample_answer', 'dataset'],\n",
      "    num_rows: 1308\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "all_qa = load_dataset(\"cardiffnlp/databench\", name=\"qa\", split=\"train\")\n",
    "print(all_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_df = pd.DataFrame()\n",
    "\n",
    "# Read the answers from the .txt files into separate lists\n",
    "with open(\"../data/answers.txt\", \"r\") as f:\n",
    "    answers = f.read().splitlines()\n",
    "\n",
    "with open(\"../data/answers_lite.txt\", \"r\") as f:\n",
    "    sample_answers = f.read().splitlines()\n",
    "\n",
    "with open(\"../data/semantics.txt\", \"r\") as f:\n",
    "    semantics = f.read().splitlines()\n",
    "\n",
    "# Combine the lists into a DataFrame\n",
    "\n",
    "# Load the dataset column from the specified file\n",
    "test_qa[\"answer\"] = answers\n",
    "test_qa[\"sample_answer\"] = sample_answers\n",
    "test_qa[\"type\"] = semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa = Dataset.from_pandas(test_qa.head(100))\n",
    "evaluator = Evaluator(qa=qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'Sales Executive', 'Sales', 'Divorced', 'Life Sciences', 'Travel_Rarely', 'Male', '3', 'Human Resources', '36.92', '9.0', '40.0', '4919.0', '13513', '11.10', '446.0', '15.0', '15.0', '[4, 3]', '[1009, 1051, 1052, 1081, 1091]', '[2, 1, 4, 3, 5]', '[25, 25, 25, 25, 25]', '[35, 34, 36, 31, 29]', \"['Sales Executive', 'Research Scientist', 'Laboratory Technician']\", \"['Research & Development', 'Sales']\", \"['Single', 'Married', 'Divorced']\", \"['Life Sciences', 'Other', 'Medical', 'Marketing', 'Technical Degree', 'Human Resources']\", \"['Travel_Rarely', 'Travel_Frequently', 'Non-Travel']\", \"['No', 'Yes']\", '[1, 2, 3, 4]', '[1, 2, 3]', 'True', 'True', 'True', '15132', 'True', 'False', 'False', 'False', 'True', 'True', '2012', '3.92', '5', '0', 'charlietrisj', '806.7501', '20000.0', '66.0', '1.1509', '12592', '2002', '1', '23020', '[2012, 2011, 2010, 2009]', '[66, 52, 47, 44, 43]', \"['Manny S', 'David S','ZP83','palmsprings0']\", \"['Manny S']\", '[3523356, 3236579, 3235844, 3235844, 3235844]', \"['2012', '2011', '2010', '2009']\", 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'Request for Quotations', 'SOUTH ASIA', \"Lao People's Democratic Republic\", 'Civil Works', 'EUROPE AND CENTRAL ASIA', 'India', 'Agriculture, Fishing and Forestry', '812960107.83', '9.0', '239461.0', '530724.5038668092', '427.0', '5652503.36', '27051', '[812960107.83, 616609217.47, 577047623.48]', 'True', '[427.0, 832.0, 1418.0, 2530.0, 3058.0 ]', '[2021, 2022, 2023]', '[15925264883.9, 13321977331.02, 13505690141.88]', '[100000.05, 100005.34]', '[321127567.87, 306306411.37, 253905847.27, 180832613.5]', \"['India', 'Western and Central Africa', 'Ethiopia', 'Madagascar', 'Bolivia']\", \"['SOUTH ASIA', 'Western and Central Africa', 'Eastern and Southern Africa', 'LATIN AMERICA AND CARIBBEAN']\", \"['Request for Bids', 'Individual Consultant Selection', 'Request for Quotations', 'Direct Selection']\", \"['Ghana', 'World', 'Burkina Faso', 'Nigeria']\", \"['Post', 'Prior']\", \"['Post', 'Prior']\", 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'Business and Finance', 'Business and Finance', 'Sports', 'Sports', '483', 'Commercial Trucks', 'Attractions', '703', '34', '85', '316', '40', '40', '8', 'True', '703', \"['483', '90', 'SPSHQ5']\", '[12, 41]', '[0, 0]', '[703, 663, 316, 60]', \"['Attractions', 'Automotive', 'Books and Literature']\", \"['Attractions', 'Automotive']\", \"['Amusement and Theme Parks', 'Bars & Restaurants', 'Casinos', 'Parks']\", \"['Attractions']\", \"['Attractions', 'Attractions', 'Attractions', 'Attractions']\", \"['150', '1', '2', '37']\", \"['150', '1', '2']\", 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'Hacendado', 'Spain', 'No gluten', '263', 'Hacendado', 'kiliweb', '8329', '29', '5423', '3420', '9102', '9483', '1913', '[00001522, 8480000041968, 8480000041975, 8480000046444, 8480000230058, 8480000865274, 8480000707000]', \"['Seitán a la plancha' ,'Seitán a la piastra' ,'Hamburguesa de seitán' ,'Seitán a la plancha' ,'Seitán' ,'Seitan' ,'Seitán a la plancha']\", \"['No gluten', 'Green Dot']\", \"['No gluten', 'Green Dot', 'No lactose', 'Vegetarian', 'Vegan']\", \"['Hacendado', 'Mercadona']\", '[4148, 3420]', \"['Spain', 'Portugal', 'France']\", '[9147, 186, 141]', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'Switzerland', 'Pakistan', 'Pakistan', 'Switzerland', 'Hong Kong (China)', 'Singapore', 'Barbados', '101.1', '46.5', '121.0', '44.22', '84.2', '72.1', '110.91', '3.0', '[46.5, 36.7, 39.2, 67.2, 19.0]', '[18.8, 20.4, 21.0, 21.2, 22.5]', '[158.7, 54.6, 120.3, 111.1, 43.5]', '[109.1, 88.4, 84.6]', '[97.0, 83.3, 86.8, 50.4, 69.4]', '[11.1, 12.7, 12.7, 12.8, 13.7]', '[99.4, 101.1, 102.4, 102.4, 102.8]', \"['Switzerland', 'Bahamas', 'Iceland', 'Singapore', 'Barbados']\", \"['Switzerland', 'Iceland', 'Hong Kong (China)']\", \"['Bangladesh', 'Pakistan', 'Nepal']\", \"['Australia', 'Austria', 'Canada', 'New Zealand', 'Ireland', 'France']\", \"['Luxembourg', 'Kuwait', 'Qatar', 'Switzerland', 'United States']\", \"['Bangladesh', 'Pakistan', 'Indonesia']\", 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', '4.0', '4.0', '4.0', '2', '2.0', '4.5', '3.0', 'True', '340.0', '109.70', '162.0', '9.7', '1.5', '0.6048128003332054', '11854.0', '108.0', '[340, 340, 340, 340, 340]', '9', '42', '[120, 120, 120, 120, 120]', '[6.8, 7.2, 7.21, 7.23, 7.25]', '[5.0, 5.0, 5.0, 5.0, 5.0]', '[5.0, 5.0, 5.0, 5.0, 5.0]', '[120, 120, 120, 120, 120]', '[340, 340]', '[7.21, 7.28]', '[4, 5, 5, 5, 5]', '[1, 1, 2, 1, 1]', '[4.0, 4.5, 4.5, 4.0]', '[4.5, 5.0, 4.0, 4.5, 4.5]', '[2.0, 2.0, 3.0, 4.0, 2.0]', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'southeast', 'male', 'yes', 'southeast', 'male', 'True', '0', 'northeast', 'no', '53.13', '1.09', '4', '17755824.99', '18', '91', '274', '30.4', '[53.13, 52.58]', '[1163.46, 44501.39, 2438.05]', '[18, 18, 18, 18, 18]', '[18, 18, 18]', \"['yes', 'no']\", \"['southeast', 'southeast', 'southeast']\", 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'True', '83 kg', '93 kg', 'Bench Press', '399.0', '10', '5', '5', '399', '399', 'Sarah Thomas', '258507.0', '100.0', '299.0', '10', '[399, 399, 399]', '[100, 100, 100, 100, 100]', '[88849, 88071, 87862, 83245, 81271]', '[46, 46, 46]', '[100, 100]', '[399, 399, 399]', \"['Emily Davis', 'Jessica Wilson', 'Jane Smith', 'Laura Taylor', 'Sarah Thomas']\", \"['Chris Brown', 'John Doe', 'Michael Johnson', 'Daniel Lee', 'Matthew Anderson']\", \"['93 kg', 'Open', '59 kg']\", \"['Laura Taylor', 'Sarah Thomas', 'Matthew Anderson', 'Jane Smith', 'Laura Taylor']\", \"['Deadlift', 'Bench Press', 'Squat']\", \"['Deadlift', 'Bench Press', 'Squat']\", 'False', 'False', 'True', 'True', 'False', 'False', 'False', 'False', 'HHS Region 04', 'Suicide', 'Male', 'Urban', 'HHS Region 04', '276.4', '0.1', '25', '22762.7', '0.640', '63.16', '10', '273.0', '[276.4, 266.4, 248.8, 246.0, 245.2]', '[0.1, 0.1, 0.1, 0.1, 0.1]', '[106.0, 106.7, 114.3, 115.1, 119.8]', '[1.4, 1.3, 1.3, 1.3]', '[0.4, 0.4, 0.4, 0.5, 0.5]', \"['Heart disease', 'Cancer', 'Lower respiratory', 'Unintentional injuries', 'Cerebrovascular diseases', 'Alzheimers', 'Diabetes', 'Flu and pneumonia', 'Suicide', 'Nephritis']\", \"['HHS Region 04', 'HHS Region 06', 'HHS Region 03']\", \"['Urban', 'Rural']\", 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'True', 'Kevin Durant', 'Kevin Durant', 'GSW', 'Steve Nash', 'GSW', 'Greivis Vasquez', 'Ricky Rubio', '191', '1348034', '320686', '76.210', '82', '907', '0', '0', '269', '[1247, 1232, 1226]', '[907, 840, 839]', '[2818, 2593, 2558, 2376]', '[191, 177, 174]', '[269, 254, 242]', \"['Harrison Barnes', 'DeMar DeRozan', 'Jeff Green', 'P.J. Tucker', 'Andre Drummond']\", '[Andre Drummond, Nikola Vucevic, Rudy Gobert]', \"['GSW', 'LAC', 'BOS', 'MIL', 'MIA']\", '[GSW, MIL, BOS, OKC, DEN]', \"['Chris Paul', 'James Harden']\", \"['Hassan Whiteside', 'Victor Wembanyama', 'Serge Ibaka']\", \"['James Harden', 'Russell Westbrook', 'Rajon Rondo', 'Chris Paul']\", 'True', 'True', 'False', 'False', 'False', 'True', 'False', '42', 'True', '0', '19', '163.0', '2.0', '31.6', '126.0', '1.35', '29.25', '1012', '30', '90', '0.61', '5.09', '[196.0, 186.0, 180.0]', '[16.0, 17.0, 18.0, 19.0]', '[1, 2, 3, 4, 5, 6, 7, 8, 9]', '[49.0, 50.0, 55.0, 66.0, 61.0]', '[0, 1]', '[0, 1]', '[165.0, 180.0, 157.0, 167.0]', '[1,2,3,4,5,6,7,8,9]', '[17, 18, 19] ', 'False', 'False', 'False', 'False', 'False', 'False', 'True', 'True', 'True', '1', '5', 'December', '11', 'Monday', 'January', '6', 'Thursday', '33.3', '0.4', '574.40', '7', '44.28', '852.7', '4.55', '247', '[33.3, 33.1, 32.6]', '[7.9, 9.3, 15.3, 15.5, 15.8]', '[2, 3, 4, 5, 6, 8, 9]', '[15, 15, 17, 18]', '[9.4, 9.4, 9.4, 9.4, 8.9]', '[6.995619625, 6.616439948, 5.633109621]', '[1.1, 2.4, 3.0]', '[January, February, March, April, May, June, July, August, September, October, November, December]', '[Monday, Thursday, Wednesday]', '[August, November]', '[Tuesday, Thursday, Saturday]', \"['December', 'August']\", \"['Wednesday', 'Monday']\", \"['Monday', 'Thursday', 'Saturday', 'Wednesday', 'Sunday', 'Friday', 'Tuesday']\", 'False', 'False', 'False', 'False', 'False', 'True', 'True', 'False', \"Hell's Kitchen\", 'Flavours', 'Sat', 'Premium Beans', 'Jun', '20', 'Lower Manhattan', 'Coffee', '8.0', '80.0', '698812.33', 'True', '3.38', '21096', '3', '360', '35352.0', '[8, 8, 8]', '[5, 8, 3]', '[0.8, 0.8, 0.8, 0.8]', '[360.0, 72.0, 56.0]', '[7, 1, 2, 3, 4, 5, 6]', '[\"Hell\\'s Kitchen\", \\'Astoria\\', \\'Lower Manhattan\\']', \"['Coffee beans', 'Branded']\", \"['Brewed Chai tea', 'Gourmet brewed coffee', 'Barista Espresso']\", \"['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\", \"['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\", '[8, 3]', \"['Premium Beans', 'Premium Beans']\", 'Civet Cat', 'True', 'True', 'True', 'True', 'False', 'False', 'True', 'True', 'How to Win Friends and Influence People', 'Novel', '1000', '10', 'Ernest Hemingway', '80', 'BPB Publications (India)', '6', 'Islamic Books', '8', '14087', '5', '20.236', '9', '498', '2', '12', '37', '[498, 640, 80, 512, 492]', '[498, 640, 80, 512, 492]', '[73.0, 85.0, 50.0, 30.0]', '[492]', '[4, 6, 21, 38, 18]', '[5.0, 0.0, 27.0, 1.0, 40.0]', '[498]', '1', \"['History and Tradition', ' Business, Investment and Economics', 'Islamic Books', 'Islamic Books', 'Computer Science & Engineering']\", \"['Harish Bhat , B.S. Badan', 'Leil Lowndes', 'Dr. Joseph Murphy']\", \"['Madinah Arabic Reader 1', 'How Harsh Mariwala ?Groomed? Marico', 'Train to Pakistan', 'The Old Man and The Sea', 'Metamorphosis', 'Animal Farm', 'The Alchemist', 'Who Moved My Cheese?', 'The Art of War']\", \"['History and Tradition', ' Business, Investment and Economics', 'Novel', 'Novel', 'Novel', 'Novel', 'Novel', 'Novel', 'Self-help and meditation', 'Self-help and meditation', 'Self-help and meditation', 'Self-help and meditation', 'Self-help and meditation', 'Self-help and meditation', ' Mystery, Detective, Thriller and Adventure']\", \"['Yuval Noah Harari', 'Benjamin Graham', 'Khaled Hosseini', 'Ernest Hemingway', 'George Orwell', 'Chetan Bhagat', 'Dale Carnegie', 'Spencer Johnson', 'Napoleon Hill', 'Dr. Joseph Murphy', 'Jack Welch, Suzy Welch', 'J. K. Rowling']\", \"['Self-help and meditation', 'Self-help and meditation', 'Self-help and meditation', 'War Tactics and Foreign Policy', ' Mystery, Detective, Thriller and Adventure']\", \"['1st Edition', 'Edition', 'Edition', '1st Published']\"]\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2027.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBench_lite accuracy is 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataBench_lite accuracy is {evaluator.eval(answers, lite=True)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
